<HTML><head><title>Flux.outputsize</title><script src=../template/highlight.min.js ></script><script src=../template/julia.min.js ></script><script src=../template/loadhighlightjs.js ></script><link href=../template/ansi.css rel=stylesheet ></link><link href=../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../README.md.html title= >README</a></p></li><li><p><a href=../docs/setup.md.html title= >Setup</a></p></li><li><p>Tutorials</p><ul><li><p><a href=../docs/introduction.md.html title= >Introduction</a></p></li><li><p><a href=../notebooks/quickstart.ipynb.html title= >Quickstart</a></p></li><li><p>Vision</p><ul><li><p><a href=../notebooks/imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=../notebooks/keypointregression.ipynb.html title= >Keypoint regression</a></p></li></ul></li><li><p>Intermediate</p><ul><li><p><a href=../docs/data_containers.md.html title= >Data containers</a></p></li><li><p><a href=../notebooks/serialization.ipynb.html title= >Saving and loading models</a></p></li></ul></li><li><p>Advanced</p><ul><li><p><a href=../notebooks/presizing.ipynb.html title= >Presizing vision datasets</a></p></li><li><p><a href=../docs/learning_methods.md.html title= >Custom Learning methods</a></p></li></ul></li></ul></li><li><p>How To</p><ul><li><p><a href=../notebooks/fitonecycle.ipynb.html title= >Train a model from scratch</a></p></li><li><p><a href=../notebooks/finetune.ipynb.html title= >Finetune a pretrained model</a></p></li><li><p><a href=../notebooks/lrfind.ipynb.html title= >Find a good learning rate</a></p></li><li><p><a href=../docs/howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=../notebooks/how_to_visualize.ipynb.html title= >Visualize data</a></p></li><li><p><a href=../docs/howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=../docs/fastai_api_comparison.md.html title= >fastai API comparison</a></p></li><li><p><a href=../docs/api.md.html title= >API</a></p></li><li><p><a href=../docs/interfaces.md.html title= >Extension APIs</a></p></li><li><p><a href=../docs/glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=../docs/background/datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><article><h1 id=fluxoutputsize ><code>Flux.outputsize</code></h1><div class=docs ><div typesig=Union{} module=Flux linenumber=114 binding=Flux.outputsize path=/home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl class=doc ><pre lang= ><code>outputsize(m, x_size, y_size, ...; padbatch=false)
</code></pre><p>For model or layer <code>m</code> accepting multiple arrays as input,
this returns <code>size(m((x, y, ...)))</code> given <code>size_x = size(x)</code>, etc.</p><h1 id=examples >Examples</h1><pre lang=jldoctest ><code>julia&gt; x, y = rand(Float32, 5, 64), rand(Float32, 7, 64);

julia&gt; par = Parallel(vcat, Dense(5, 9), Dense(7, 11));

julia&gt; Flux.outputsize(par, (5, 64), (7, 64))
(20, 64)

julia&gt; m = Chain(par, Dense(20, 13), softmax);

julia&gt; Flux.outputsize(m, (5,), (7,); padbatch=true)
(13, 1)

julia&gt; par(x, y) == par((x, y)) == Chain(par, identity)((x, y))
true
</code></pre><p>Notice that <code>Chain</code> only accepts multiple arrays as a tuple,
while <code>Parallel</code> also accepts them as multiple arguments;
<code>outputsize</code> always supplies the tuple.</p></div><div typesig=Tuple{Any, Vararg{Tuple, N} where N} module=Flux linenumber=50 binding=Flux.outputsize path=/home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl class=doc ><pre lang= ><code>outputsize(m, inputsize::Tuple; padbatch=false)
</code></pre><p>Calculate the size of the output from model <code>m</code>, given the size of the input.
Obeys <code>outputsize(m, size(x)) == size(m(x))</code> for valid input <code>x</code>.</p><p>Keyword <code>padbatch=true</code> is equivalent to using <code>(inputsize..., 1)</code>, and
returns the final size including this extra batch dimension.</p><p>This should be faster than calling <code>size(m(x))</code>. It uses a trivial number type,
which should work out of the box for custom layers.</p><p>If <code>m</code> is a <code>Tuple</code> or <code>Vector</code>, its elements are applied in sequence, like <code>Chain(m...)</code>.</p><h1 id=examples >Examples</h1><pre lang=julia-repl ><code>julia&gt; using Flux: outputsize

julia&gt; outputsize(Dense(10, 4), (10,); padbatch=true)
(4, 1)

julia&gt; m = Chain(Conv((3, 3), 3 =&gt; 16), Conv((3, 3), 16 =&gt; 32));

julia&gt; m(randn(Float32, 10, 10, 3, 64)) |&gt; size
(6, 6, 32, 64)

julia&gt; outputsize(m, (10, 10, 3); padbatch=true)
(6, 6, 32, 1)

julia&gt; outputsize(m, (10, 10, 3, 64))
(6, 6, 32, 64)

julia&gt; try outputsize(m, (10, 10, 7, 64)) catch e println(e) end
┌ Error: layer Conv((3, 3), 3=&gt;16), index 1 in Chain, gave an error with input of size (10, 10, 7, 64)
└ @ Flux ~/.julia/dev/Flux/src/outputsize.jl:114
DimensionMismatch(&quot;Input channels must match! (7 vs. 3)&quot;)

julia&gt; outputsize([Dense(10, 4), Dense(4, 2)], (10, 1)) # Vector of layers becomes a Chain
(2, 1)
</code></pre></div><h2 id=methods >Methods</h2># 4 methods for generic function <b>outputsize</b>:<ul><li> outputsize(m::<b>Chain</b>, inputsizes::<b>Tuple{Vararg{Integer, N} where N}...</b>; <i>padbatch</i>) in Flux at <a href="file:///home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl" target="_blank">/home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl:100</a></li> <li> outputsize(m::<b>Tuple</b>, input::<b>Tuple...</b>; <i>padbatch</i>) in Flux at <a href="file:///home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl" target="_blank">/home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl:145</a></li> <li> outputsize(m::<b>AbstractVector{T} where T</b>, input::<b>Tuple...</b>; <i>padbatch</i>) in Flux at <a href="file:///home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl" target="_blank">/home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl:146</a></li> <li> outputsize(m, inputsizes::<b>Tuple...</b>; <i>padbatch</i>) in Flux at <a href="file:///home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl" target="_blank">/home/runner/.julia/packages/Flux/Zz9RI/src/outputsize.jl:91</a></li> </ul></div></article></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#fluxoutputsize >Flux.outputsize</a><ul></ul></li></ul></nav></aside></main></body></HTML>