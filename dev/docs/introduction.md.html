<HTML><head><title>Introduction</title><script src=../template/highlight.min.js ></script><script src=../template/julia.min.js ></script><script src=../template/loadhighlightjs.js ></script><link href=../template/ansi.css rel=stylesheet ></link><link href=../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../README.md.html title= >README</a></p></li><li><p><a href=setup.md.html title= >Setup</a></p></li><li><p><a href=../notebooks/quickstart.ipynb.html title= >Quickstart</a></p></li><li><p>Tutorials</p><ul><li><p>Beginner</p><ul><li><p><a href=introduction.md.html title= >Introduction</a></p></li><li><p><a href=discovery.md.html title= >Discovery</a></p></li></ul></li><li><p>Intermediate</p><ul><li><p><a href=../notebooks/imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=../notebooks/keypointregression.ipynb.html title= >Keypoint regression</a></p></li><li><p><a href=../notebooks/tabularclassification.ipynb.html title= >Tabular classification</a></p></li><li><p><a href=data_containers.md.html title= >Data containers</a></p></li><li><p><a href=../notebooks/serialization.ipynb.html title= >Saving and loading models</a></p></li></ul></li><li><p>Advanced</p><ul><li><p><a href=../notebooks/presizing.ipynb.html title= >Presizing vision datasets</a></p></li><li><p><a href=learning_methods.md.html title= >Custom Learning methods</a></p></li></ul></li></ul></li><li><p>How To</p><ul><li><p><a href=../notebooks/training.ipynb.html title= >Train your model</a></p></li><li><p><a href=howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=fastai_api_comparison.md.html title= >fastai API comparison</a></p></li><li><p><a href=interfaces.md.html title= >Extension APIs</a></p></li><li><p><a href=glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=background/blocksencodings.md.html title= >Blocks and encodings</a></p></li><li><p><a href=background/datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><h1 id=introduction >Introduction</h1><p><em>This tutorial explains the qickstart examples and some core abstractions FastAI.jl is built on.</em></p><div result=false class=cellcontainer cell=main lang=julia style=display:none; ><pre result=false class=codecell cell=main lang=julia style=display:none; ><code>using FastAI
</code></pre></div><p>On the <a href=../notebooks/quickstart.ipynb.html title= >quickstart page</a>, we showed how to train models on common tasks in a few lines of code like these:</p><pre lang=julia ><code>using FastAI
data, blocks = loaddataset(&quot;imagenette2-160&quot;, (Image, Label))
method = ImageClassificationSingle(blocks)
learner = methodlearner(method, data, callbacks=[ToGPU()])
fitonecycle!(learner, 10)
showoutputs(method, learner)
</code></pre><p>Each of the five lines encapsulates one part of the deep learning pipeline to give a high-level API while still allowing customization. Let’s have a closer look.</p><h2 id=dataset >Dataset</h2><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>data, blocks = loaddataset(&quot;imagenette2-160&quot;, (Image, Label))
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:Image))</code></pre></div><p>This line downloads and loads the <a href=https://github.com/fastai/imagenette title= >ImageNette</a> image classification dataset, a small subset of ImageNet with 10 different classes. <code>data</code> is a <a href=./data_containers.md.html title= >data container</a> that can be used to load individual observations, here of images and the corresponding labels. We can use <code>getobs(data, i)</code> to load the <code>i</code>-th observation and <code>nobs</code> to find out how many observations there are.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>image, class = sample =  getobs(data, 1000)
@show class
image
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:data))</code></pre></div><p><code>blocks</code> describe the format of the data that you want to use for learning. For supervised training tasks, they are a tuple of <code>(inputblock, targetblock)</code>. Since we want to do image classification, the input block is <code>Image{2}()</code>, representing a 2-dimensional image and the target block is <code>Label(classes)</code>, representing the class the image belongs to.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>blocks
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:blocks))</code></pre></div><h2 id=learning-method >Learning method</h2><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>method = ImageClassificationSingle(blocks)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:blocks))</code></pre></div><p>The next line defines a learning method which encapsulates the data preprocessing pipeline and other logic related to the task. <code>ImageClassificationSingle</code> is a simple wrapper around <code>BlockMethod</code> which takes in blocks and data processing steps, so-called <em>encodings</em>. Using it, we can replace the above line with</p><pre lang=julia ><code>method = BlockMethod(
    (Image{2}(), Label(classes)),
    (
        ProjectiveTransforms((128, 128)),
        ImagePreprocessing(),
        OneHot()
    )
)
</code></pre><p>Based on the blocks and encodings, the learning method can derive lots of functionality:</p><ul><li><p>data processing</p></li><li><p>visualization</p></li><li><p>constructing task-specific models from a backbone</p></li><li><p>creating a loss function</p></li></ul><h2 id=learner >Learner</h2><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>learner = methodlearner(method, data, callbacks=[ToGPU(), Metrics(accuracy)])
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:method))</code></pre></div><p>Next we create a <a href=../REFERENCE/FluxTraining.Learner.html ><code>Learner</code></a> that encapsulates everything needed for training, including:</p><ul><li><p>parallelized training and validation data loaders using <a href=../REFERENCE/DLPipelines.methoddataloaders.html ><code>DLPipelines.methoddataloaders</code></a></p></li><li><p>a loss function using <a href=../REFERENCE/DLPipelines.methodlossfn.html ><code>DLPipelines.methodlossfn</code></a></p></li><li><p>a task-specific model using <a href=../REFERENCE/DLPipelines.methodmodel.html ><code>DLPipelines.methodmodel</code></a></p></li></ul><p>The customizable, expanded version of the code looks like this:</p><pre lang=julia ><code>dls = methoddataloaders(data, method)
model = methodmodel(method, Models.xresnet18())
lossfn = methodlossfn(method)
learner = Learner(model, dls, ADAM(), lossfn, ToGPU(), Metrics(accuracy))
</code></pre><p>At this step, we can also pass in any number of <a href=https://fluxml.ai/FluxTraining.jl/dev/docs/callbacks/reference.md.html title= >callbacks</a> to customize the training. Here <a href=../REFERENCE/FluxTraining.ToGPU.html ><code>ToGPU</code></a> ensures an available GPU is used, and <a href=../REFERENCE/FluxTraining.Metrics.html ><code>Metrics</code></a> adds additional metrics to track during training.</p><h2 id=training >Training</h2><pre lang=julia ><code>fitonecycle!(learner, 10)
</code></pre><p>Training now is quite simple. You have several options for high-level training schedules:</p><ul><li><p><a href=../REFERENCE/FastAI.lrfind.html ><code>lrfind</code></a> to run a learning rate finder</p></li><li><p><a href=../REFERENCE/FastAI.finetune!.html ><code>finetune!</code></a> for when you’re using a pretrained backbone</p></li><li><p><a href=../REFERENCE/FastAI.fitonecycle!.html ><code>fitonecycle!</code></a> for when you’re training a model from scratch</p></li></ul><h2 id=visualization >Visualization</h2><pre lang=julia ><code>showoutputs(method, learner)
</code></pre><p>Finally, the last line visualizes the predictions of the trained model. It takes some samples from the training data loader, runs them through the model and decodes the outputs. How each piece of data is visualized is also inferred through the blocks in the learning method.</p></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#introduction >Introduction</a><ul><li><a href=#dataset >Dataset</a><ul></ul></li><li><a href=#learning-method >Learning method</a><ul></ul></li><li><a href=#learner >Learner</a><ul></ul></li><li><a href=#training >Training</a><ul></ul></li><li><a href=#visualization >Visualization</a><ul></ul></li></ul></li></ul></nav></aside></main></body></HTML>