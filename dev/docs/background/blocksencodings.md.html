<HTML><head><title>Blocks and encodings</title><script src=../../template/highlight.min.js ></script><script src=../../template/julia.min.js ></script><script src=../../template/loadhighlightjs.js ></script><link href=../../template/ansi.css rel=stylesheet ></link><link href=../../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FastAI.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../../README.md.html title= >README</a></p></li><li><p><a href=../setup.md.html title= >Setup</a></p></li><li><p><a href=../../notebooks/quickstart.ipynb.html title= >Quickstart</a></p></li><li><p>Tutorials</p><ul><li><p>Beginner</p><ul><li><p><a href=../introduction.md.html title= >Introduction</a></p></li><li><p><a href=../discovery.md.html title= >Discovery</a></p></li></ul></li><li><p>Intermediate</p><ul><li><p><a href=../../notebooks/imagesegmentation.ipynb.html title= >Image segmentation</a></p></li><li><p><a href=../../notebooks/keypointregression.ipynb.html title= >Keypoint regression</a></p></li><li><p><a href=../../notebooks/tabularclassification.ipynb.html title= >Tabular classification</a></p></li><li><p><a href=../data_containers.md.html title= >Data containers</a></p></li><li><p><a href=../../notebooks/serialization.ipynb.html title= >Saving and loading models</a></p></li></ul></li><li><p>Advanced</p><ul><li><p><a href=../../notebooks/presizing.ipynb.html title= >Presizing vision datasets</a></p></li><li><p><a href=../learning_methods.md.html title= >Custom Learning methods</a></p></li></ul></li></ul></li><li><p>How To</p><ul><li><p><a href=../../notebooks/training.ipynb.html title= >Train your model</a></p></li><li><p><a href=../howto/augmentvision.md.html title= >Augment vision data</a></p></li><li><p><a href=../howto/logtensorboard.md.html title= >Log to TensorBoard</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=../fastai_api_comparison.md.html title= >fastai API comparison</a></p></li><li><p><a href=../interfaces.md.html title= >Extension APIs</a></p></li><li><p><a href=../glossary.md.html title= >Glossary</a></p></li></ul></li><li><p>Background</p><ul><li><p><a href=blocksencodings.md.html title= >Blocks and encodings</a></p></li><li><p><a href=datapipelines.md.html title= >Performant data pipelines</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><h1 id=blocks-and-encodings >Blocks and encodings</h1><p><em>Unstructured notes on blocks and encodings</em></p><h2 id=blocks >Blocks</h2><blockquote><p>A <strong>block</strong> describes the meaning of a piece of data in the context of a learning task.</p></blockquote><ul><li><p>For example, for supervised learning tasks, there is an input block and a target block and we want to learn to predict targets from inputs. Learning to predict a cat/dog label (<code>Label([&quot;cat&quot;, &quot;dog&quot;])</code>) from 2D images (<code>Image{2}()</code>) is a supervised image classification task.</p></li><li><p>A block is not a piece of data itself. Instead it describes the meaning of a piece of data in a context. That a piece of data is a block can be checked using [<code>checkblock</code>]<code>(block, data)</code>. A piece of data for the <code>Label</code> block above needs to be one of the labels, so <code>checkblock(Label([&quot;cat&quot;, &quot;dog&quot;]), &quot;cat&quot;) == true</code>, but <code>checkblock(Label([&quot;cat&quot;, &quot;dog&quot;]), &quot;cat&quot;) == false</code>.</p></li><li><p>We can say that a data container is compatible with a learning method if every observation in it is a valid sample of the sample block of the learning method. The sample block for supervised tasks is <code>sampleblock = (inputblock, targetblock)</code> so <code>sample = getobs(data, i)</code> from a compatible data container implies that <code>checkblock(sampleblock, sample)</code>. This also means that any data stored in blocks must not depend on individual samples; we can store the names of possible classes inside the <code>Label</code> block because they are the same across the whole dataset.</p></li></ul><h2 id=data-pipelines >Data pipelines</h2><p>We can use blocks to formalize the data processing pipeline.</p><p>During <strong>training</strong> we want to create pairs of data <code>(x, y)</code> s.t. <code>output = model(x)</code> and <code>loss = lossfn(output, y)</code>. In terms of blocks that means <code>model</code> is a function <code>(x,) -&gt; output</code> and the loss function maps <code>(outputblock, yblock) -&gt; loss</code>. Usually, <code>(input, target) != (x, y)</code> and instead we have an encoding step that transforms a sample into representations suitable to train a model on, i.e. <code>encode :: sample -&gt; (x, y)</code>.</p><ul><li><p>For the above image classification example we have <code>sampleblock = (Image{2}(), Label([&quot;cat&quot;, &quot;dog&quot;]))</code> but we cannot put raw images into a model and get out a class. Instead, the image is converted to an array that includes the color dimension and its values are normalized; and the class label is one-hot encoded. So <code>xblock = ImageTensor{2}()</code> and <code>yblock = OneHotTensor{0}</code>. Hence to do training, we need a sample encoding function <code>(Image{2}, Label) -&gt; (ImageTensor{2}, OneHotTensor{0})</code></p></li></ul><p>During <strong>inference</strong>, we have an input and want to use a trained model to predict a target, i.e. <code>input -&gt; target</code>. The model is again a mapping <code>xblock -&gt; outputblock</code>, so we can build the transformation with an encoding step that encodes the input and a decoding step that takes the model output back into a target.</p><p>This gives us</p><blockquote><p><code>(predict :: input -&gt; target) = decodeoutput ∘ model ∘ encodeinput</code><br></br>where</p><ul><li><p><code>(encodeinput :: input -&gt; x)</code></p></li><li><p><code>(model :: x -&gt; y)</code></p></li><li><p><code>(decodeoutput :: y -&gt; target)</code></p></li></ul></blockquote><ul><li><p>In the classification example we have, written in blocks, <code>predict :: Image{2} -&gt; Label</code> and hence <code>encodeinput :: Image{2} -&gt; ImageTensor{2}</code> and <code>decodeoutput :: OneHotTensor{0} -&gt; Label</code></p></li></ul><p>Where do we draw the line between model and data processing? In general, the encoding and decoding steps are <strong>non-learnable</strong> transformations, while the model is a <strong>learnable</strong> transformation.</p><h2 id=encodings >Encodings</h2><blockquote><p><strong>Encodings</strong> are reversible transformations that model the non-learnable parts (encoding and decoding) of the data pipeline.</p></blockquote><ul><li><p>What an encoding does depends on what block is passed in. Most encodings only transform specific blocks. For example, the <a href=../../REFERENCE/FastAI.ImagePreprocessing.html ><code>ImagePreprocessing</code></a> encoding maps blocks <code>Image{N} -&gt; ImageTensor{N}</code>, but leaves other blocks unchanged. Encodings are called with <code>encode</code> and <code>decode</code> which take in the block and the data. The actual encoding and decoding takes in an additional context argument which can be specialized on to implement different behavior for e.g. training and validation.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>using FastAI, Colors
using FastAI: ImageTensor
enc = ImagePreprocessing()
data = rand(RGB, 100, 100)
@show summary(data)
encdata = encode(enc, Training(), Image{2}(), data)
@show summary(encdata)  # (h, w, ch)-image tensor
data_ = decode(enc, Training(), ImageTensor{2}(3), encdata)
</code></pre><pre class=coderesult ><code>LoadError("string", 2, UndefVarError(:ImageTensor))</code></pre></div></li><li><p>Using an encoding to encode and then decode must be block-preserving, i.e. if, for an encoding, <code>encode :: Block1 -&gt; Block2</code> then <code>decode :: Block2 -&gt; Block1</code>. To see the resulting block of applying an encoding to a block, we can use <a href=../../REFERENCE/FastAI.encodedblock.html ><code>FastAI.encodedblock</code></a> and <a href=../../REFERENCE/FastAI.decodedblock.html ><code>FastAI.decodedblock</code></a>.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>using FastAI: encodedblock, decodedblock
enc = ImagePreprocessing()
@show encodedblock(enc, Image{2}())
@show decodedblock(enc, ImageTensor{2}(3))
Image{2}() == decodedblock(enc, encodedblock(enc, Image{2}()))
</code></pre><pre class=coderesult ><code>LoadError("string", 3, UndefVarError(:Image))</code></pre></div><p>You can use <a href=../../REFERENCE/FastAI.testencoding.html ><code>FastAI.testencoding</code></a> to test these invariants to make sure an encoding is implemented properly for a specific block.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>FastAI.testencoding(enc, Image{2}())
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:Image))</code></pre></div></li><li><p>The default implementations of <code>encodedblock</code> and <code>decodedblock</code> is to return <code>nothing</code> indicating that it doesn’t transform the data. This is overwritten for blocks for which <code>encode</code> and <code>decode</code> are implemented to indicate that the data is transformed. Using <code>encodedblockfilled(block, data)</code> will replace returned <code>nothing</code>s with the unchanged block.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>encodedblock(enc, Label(1:10)) === nothing
</code></pre><pre class=coderesult ><code>true</code></pre></div><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>encodedblockfilled(enc, Label(1:10)) == Label(1:10)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:encodedblockfilled))</code></pre></div></li><li><p>Encodings can be applied to tuples of blocks. The default behavior is to apply the encoding to each block separately.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>encodedblock(enc, (Image{2}(), Image{2}()))
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:Image))</code></pre></div></li><li><p>Applying a tuple of encodings will encode the data by applying one encoding after the other. When decoding, the order is reversed.</p></li></ul><h2 id=block-learning-methods >Block learning methods</h2><p><a href=../../REFERENCE/FastAI.BlockMethod.html ><code>BlockMethod</code></a> creates a learning method from blocks and encodings. You define the sample block (recall for supervised tasks this is a tuple of input and target) and a sequence of encodings that are applied to all blocks.</p><p>The below example defines the same learning method as <a href=../../REFERENCE/FastAI.Vision.Vision.ImageClassificationSingle.html ><code>FastAI.Vision.ImageClassificationSingle</code></a> does. The first two encodings only change <code>Image</code>, and the last changes only <code>Label</code>, so it’s simple to understand.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>method = BlockMethod(
    (Image{2}(), Label([&quot;cats&quot;, &quot;dogs&quot;])),
    (
        ProjectiveTransforms((128, 128)),
        ImagePreprocessing(),
        OneHot(),
    )
)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:Image))</code></pre></div><p>Now <code>encode</code> expects a sample and just runs the encodings over that, giving us an encoded input <code>x</code> and an encoded target <code>y</code>.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>data = loadfolderdata(joinpath(datasetpath(&quot;dogscats&quot;), &quot;train&quot;), filterfn=isimagefile, loadfn=(loadfile, parentname))
sample = getobs(data, 1)
x, y = encode(method, Training(), sample)
summary(x), summary(y)
</code></pre><pre class=codeoutput ><code>
7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21
p7zip Version 16.02 (locale=C.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU E5-2673 v3 @ 2.40GHz (306F2),ASM,AES-NI)


Extracting archive: 
--
Path = 
Type = tar
Code Page = UTF-8

Everything is Ok

Folders: 15
Files: 37526
Size:       857996848
Compressed: 19231232
</code></pre><pre class=coderesult ><code>LoadError("string", 3, UndefVarError(:method))</code></pre></div><p>This is equivalent to:</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>x, y = encode(method.encodings, Training(), method.blocks, sample)
summary(x), summary(y)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:method))</code></pre></div><p>Image segmentation looks almost the same except we use a <code>Mask</code> block as target. We’re also using <code>OneHot</code> here, because it also has an <code>encode</code> method for <code>Mask</code>s. For this method, <code>ProjectiveTransforms</code> will be applied to both the <code>Image</code> and the <code>Mask</code>, using the same random state for cropping and augmentation.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>method = BlockMethod(
    (Image{2}(), Mask{2}(1:10)),
    (
        ProjectiveTransforms((128, 128)),
        ImagePreprocessing(),
        OneHot(),
    )
)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:Image))</code></pre></div><p>The easiest way to understand how encodings are applied to each block is to use <a href=../../REFERENCE/FastAI.describemethod.html ><code>describemethod</code></a> and <a href=../../REFERENCE/FastAI.describeencodings.html ><code>FastAI.describeencodings</code></a> which print a table of how each encoding is applied successively to each block. Rows where a block is <strong>bolded</strong> indicate that the data was transformed by that encoding.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>describemethod(method)
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:method))</code></pre></div><p>The above tables make it clear what happens during training (“encoding a sample”) and inference (encoding an input and “decoding an output”). The more general form <a href=../../REFERENCE/FastAI.describeencodings.html ><code>FastAI.describeencodings</code></a> takes in encodings and blocks directly and can be useful for building an understanding of how encodings apply to some blocks.</p><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>FastAI.describeencodings(method.encodings, (Image{2}(),))
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:method))</code></pre></div><div class=cellcontainer cell=main lang=julia ><pre class=codecell cell=main lang=julia ><code>FastAI.describeencodings((OneHot(),), (Label(1:10), Mask{2}(1:10), Image{2}()))
</code></pre><pre class=coderesult ><code>LoadError("string", 1, UndefVarError(:Image))</code></pre></div><p>Notes</p><ul><li><p>Since most encodings just operate on a small number of blocks and keep the rest unchanged, applying them to all blocks is usually not a problem. When it is because you want some encoding to apply to a specific block only, you can use <a href=../../REFERENCE/FastAI.Named.html ><code>Named</code></a> and <a href=../../REFERENCE/FastAI.Only.html ><code>Only</code></a> to get around it.</p></li></ul></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#blocks-and-encodings >Blocks and encodings</a><ul><li><a href=#blocks >Blocks</a><ul></ul></li><li><a href=#data-pipelines >Data pipelines</a><ul></ul></li><li><a href=#encodings >Encodings</a><ul></ul></li><li><a href=#block-learning-methods >Block learning methods</a><ul></ul></li></ul></li></ul></nav></aside></main></body></HTML>